<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!-- saved from url=(0028)https://prova-lab.github.io/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Radoslaw Cigdem</title>
	<meta name="robots" content="follow,index">
	<meta name="Keywords" content="eca, affect, emotion, informatyka afektywna, greta, multimodal, multimedialny, agent, affective computing, avatar, awatar, nonverbal communication, komunikacja nonwerbalna, virtual agents, expressivity, multimodal, humanoid, emotions, expressions, multimedia, digital art, signal social processing, laughter, detection, recognition, multimodal, personality, nonverbal, karate, respiration, recognition, dance, ssp, social, touch">
  
  <link rel="stylesheet" type="text/css" href="./Radoslaw Niewiadomski_files/style.css" media="screen">
  
 <style type="text/css">.backpack.dropzone {
  font-family: 'SF UI Display', 'Segoe UI';
  font-size: 15px;
  text-align: center;
  display: flex;
  flex-direction: column;
  justify-content: center;
  align-items: center;
  width: 250px;
  height: 150px;
  font-weight: lighter;
  color: white;
  will-change: right;
  z-index: 2147483647;
  bottom: 20%;
  background: #333;
  position: fixed;
  user-select: none;
  transition: left .5s, right .5s;
  right: 0px; }
  .backpack.dropzone .animation {
    height: 80px;
    width: 250px;
    background: url("chrome-extension://lifbcibllhkdhoafpjfnlhfpfgnpldfl/assets/backpack/dropzone/hoverstate.png") left center; }
  .backpack.dropzone .title::before {
    content: 'Save to'; }
  .backpack.dropzone.closed {
    right: -250px; }
  .backpack.dropzone.hover .animation {
    animation: sxt-play-anim-hover 0.91s steps(21);
    animation-fill-mode: forwards;
    background: url("chrome-extension://lifbcibllhkdhoafpjfnlhfpfgnpldfl/assets/backpack/dropzone/hoverstate.png") left center; }

@keyframes sxt-play-anim-hover {
  from {
    background-position: 0px; }
  to {
    background-position: -5250px; } }
  .backpack.dropzone.saving .title::before {
    content: 'Saving to'; }
  .backpack.dropzone.saving .animation {
    background: url("chrome-extension://lifbcibllhkdhoafpjfnlhfpfgnpldfl/assets/backpack/dropzone/saving_loop.png") left center;
    animation: sxt-play-anim-saving steps(59) 2.46s infinite; }

@keyframes sxt-play-anim-saving {
  100% {
    background-position: -14750px; } }
  .backpack.dropzone.saved .title::before {
    content: 'Saved to'; }
  .backpack.dropzone.saved .animation {
    background: url("chrome-extension://lifbcibllhkdhoafpjfnlhfpfgnpldfl/assets/backpack/dropzone/saved.png") left center;
    animation: sxt-play-anim-saved steps(20) 0.83s forwards; }

@keyframes sxt-play-anim-saved {
  100% {
    background-position: -5000px; } }
</style></head><body>

<div id="navcontainer">

<ul id="navlist">
<li><a href="https://prova-lab.github.io/index.html">Home</a></li>
<li><a href="https://prova-lab.github.io/research.html">Research</a></li>
<li><a href="https://prova-lab.github.io/papers.html">Publications</a></li>
<li><a href="https://prova-lab.github.io/others.html">Datasets</a></li>
<li><a href="https://prova-lab.github.io/#"></a></li>
</ul>

</div>
	

<h1>Radosław Niewiadomski</h1> 
<table border="0"><tbody><tr valign="top"><td>
<p id="content2"><big> 
My research interests are in the area of Affective and Social Computing and include recognition of emotions, nonverbal behavior synthesis, 
creation of embodied conversational agents and interactive multimodal systems. 
<br>
<br>
I have been involved in several FP6, FP7 and H2020 EU research projects among which are FP6 CALLAS, FP7 ILHAIRE and H2020 DANCE. 
</big>
</p></td><td width="20"></td><td><br><img src="./Radoslaw Niewiadomski_files/ilhaire_me_small2.jpg" width="250"></td></tr></tbody></table>
<br>

<table border="0"><tbody><tr valign="top"><td>
<div id="content">
I obtained my Ph.D. in 2007 from the University of Perugia, Italy, under the supervision of Prof. Giulianella Coletti and Prof. Catherine Pelachaud. 
The dissertation titled <i>A model of complex facial expressions in interpersonal relations</i> presents an application of fuzzy methods to generation of facial expressions of virtual agents (see <a href="https://prova-lab.github.io/papers/ijhcs2010_niewiadomski_draft.pdf">here</a> for details).
<br>
<br>
Next, I was a postdoctoral researcher in the <a href="http://www.tsi.telecom-paristech.fr/mm/en/">Multimedia Group</a> 
at the Telecom ParisTech and in the LINC lab at the University Paris 8 working in the following EU projects: FP7 FET ILHAIRE, FP7 NoE <a href="http://sspnet.eu/">SSPNET</a> and FP6 <a href="http://www.callas-newmedia.eu/">CALLAS</a> and national project ANR CECIL (ANR-08-CORD-005).
My research projects focused mainly on modeling expessive behaviors in virtual agents. 
I was also participating in the development of the Embodied Conversational Agent called <a href="https://github.com/gretaproject/greta">Greta</a> 
(see <a href="https://prova-lab.github.io/papers/WEB3d11_niewiadomskietal.pdf">here</a> for details).
<br>
<br>
I also worked at the <a href="http://www.infomus.org/">InfoMus Lab</a> (University of Genoa) on analysis and recognition of full-body expressive behaviors.  
Among others, I was WP leader of the H2020 ICT <a href="http://dance.dibris.unige.it/">DANCE</a> Project on the analysis and sonification of the expressive movement qualities in dance performances. I was also involved in the FP7 FET <a href="http://ilhaire.eu/">ILHAIRE</a> Project aimed at the analysis and synthesis of multimodal laughter to increase the quality of human-machine interaction, H2020 <a href="https://www.wedraw.eu/"> WeDraw </a> and H2020 <a href="http://www.wholodance.eu/"> WhoLoDancE </a> Projects.
<br>
<br>
Currently, I work at the <a href="https://www.iit.it/it/research/lines/cognitive-architecture-for-collaborative-technologies">CONTACT UNIT</a> at <a href="https://www.iit.it/"> Istituto Italiano di Tecnologia</a>.
<br>
<br>
I have published over 50 peer-reviewed <a href="https://prova-lab.github.io/papers.html">conference and journal</a> papers. 
<br>
I was involved in the creation of several freely available datasets on 
<a href="http://www.infomus.org/ILHAIRE/mmli/">full-body laughter expressions</a>, 
<a href="http://www.infomus.org/eyesweb_dataset_karate_eng.php">karate </a>, or 
<a href="http://dance.dibris.unige.it/index.php/dance-datasets/expressive-vocabulary-data">expressive qualities in dance</a>.
<br>
On a regular basis I serve as a reviewer for various international conferences and journals (e.g., multiple IEEE Transactions).
<br>
I was Guest Editor of the <a href="https://ieeexplore.ieee.org/document/8119741">Special Section dedicated to laughter computing</a> of IEEE Transactions on Affective Computing.
<br>
<br>
For updated CV, please check <a href="https://prova-lab.github.io/others/CV_Niewiadomski.pdf"> here</a>.
<br>
<br>
Visit my profile on <a href="http://scholar.google.com/citations?user=CcrCL8cAAAAJ&amp;hl">Google Scholar</a>, on 
<a href="http://www.researchgate.net/profile/Radoslaw_Niewiadomski/">ResearchGate</a>, 
<a href="http://www.scopus.com/authid/detail.url?authorId=55911729200">SCOPUS</a>,
<a href="http://orcid.org/0000-0002-0476-0803">ORCID</a>.
<p></p>
<br>
</div></td>
</tr>
</tbody></table>
email: <i> {nome}.{niewiadomski}{at} iit {.} {it} 

 
</i></body></html>